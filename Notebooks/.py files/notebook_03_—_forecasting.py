# -*- coding: utf-8 -*-
"""Notebook_03_—_Forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T9YP3B3OgOOPVxt4chdSmD299bYYwwhW
"""

from google.colab import files
files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error
import math
import joblib
from datetime import timedelta

# Load merged dataset
df = pd.read_csv("/content/data/merged/nyc_demand_weather_merged.csv", parse_dates=["pickup_hour"])
df = df.sort_values("pickup_hour").reset_index(drop=True)

# Quick check
df.head()

# Basic time features
df['hour'] = df['pickup_hour'].dt.hour
df['dayofweek'] = df['pickup_hour'].dt.dayofweek
df['is_weekend'] = df['dayofweek'] >= 5
df['day'] = df['pickup_hour'].dt.day

# Fill missing numeric weather if any
for c in ['tmpf','dwpf','relh','sknt','mslp','p01i']:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors='coerce')
df = df.interpolate(limit_direction='both')

# Target
df = df.rename(columns={'pickup_hour':'ds','trip_count':'y'})  # Prophet-friendly names
df = df[['ds','y','hour','dayofweek','is_weekend','tmpf','relh','p01i']].copy()
df.head()

# Keep last 7 days as test set
horizon_days = 7
horizon_hours = horizon_days * 24

train = df.iloc[:-horizon_hours].copy()
test  = df.iloc[-horizon_hours:].copy()

print("Train rows:", len(train), "Test rows:", len(test))

# Seasonal naive: predict value = last week's same hour (24*7 lag average)
lag = 24*7
train_idx = train.index
# create naive predictions for test using train tail
naive_preds = []
for idx, row in test.iterrows():
    ref_idx = idx - lag
    if ref_idx >= 0:
        naive_preds.append(df.loc[ref_idx, 'y'])
    else:
        # fallback to hourly average from training
        naive_preds.append(train[train['hour']==row['hour']]['y'].mean())

test['naive_pred'] = naive_preds

"""For Prophet model
NeuralProphet force UTC conversion internally, and everything we do is undone by them so we skip this and move to XGBoost
"""

import pandas as pd

merged = pd.read_csv('/content/data/merged/nyc_demand_weather_merged.csv')

# Identify timestamp column (likely named 'hour' or 'pickup_hour')
print(merged.columns)

# Rename columns to standard format
merged = merged.rename(columns={
    'pickup_hour': 'ds',
    'trip_count': 'y'
})

# Convert timestamp to datetime
merged['ds'] = pd.to_datetime(merged['ds'])

merged.head(), merged.shape

# Add time-based features
merged['hour'] = merged['ds'].dt.hour
merged['weekday'] = merged['ds'].dt.weekday

# Select features
features = ['hour', 'weekday', 'tmpf', 'relh', 'p01i']
X = merged[features]
y = merged['y']

# Train-test split
split = int(len(merged) * 0.8)
X_train, X_test = X.iloc[:split], X.iloc[split:]
y_train, y_test = y.iloc[:split], y.iloc[split:]

from xgboost import XGBRegressor

model = XGBRegressor(
    n_estimators=300,
    learning_rate=0.1,
    max_depth=6,
    subsample=0.9,
    colsample_bytree=0.8,
    random_state=42
)

model.fit(X_train, y_train)

from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

preds = model.predict(X_test)

mae = mean_absolute_error(y_test, preds)
rmse = np.sqrt(mean_squared_error(y_test, preds))

mae, rmse

import matplotlib.pyplot as plt

plt.figure(figsize=(14,5))
plt.plot(y_test.values, label='Actual')
plt.plot(preds, label='Forecast')
plt.legend()
plt.title("Taxi Demand Forecast - XGBoost")
plt.show()

"""Model Performance Summary — XGBoost (NYC Taxi Demand Forecasting)

| Metric   | Score                | Interpretation                                                |
| -------- | -------------------- | ------------------------------------------------------------- |
| **MAE**  | **16.71 trips/hour** | On average, predictions are within ~17 rides of actual demand |
| **RMSE** | **21.82 trips/hour** | Larger errors slightly penalized, still quite strong          |

✔ Strong capture of daily seasonality (morning + evening peaks)

✔ Solid alignment during both high-demand and low-demand hours

✔ Model slightly underestimates extreme peaks — common and fixable with more features (e.g., event data, holidays)

Taxi demand is highly predictable using time-based features and weather.
The model achieved low error (MAE ≈ 16.7) and accurately captures peak demand cycles, enabling better fleet planning and driver deployment.
"""

import matplotlib.pyplot as plt
from xgboost import plot_importance

plt.figure(figsize=(8,5))
plot_importance(model)
plt.title("Feature Importance - XGBoost")
plt.show()

plt.figure(figsize=(14,5))
plt.plot(range(len(y_test)), y_test, label='Actual', color='#FFC300', linewidth=2)
plt.plot(range(len(preds)), preds, label='Forecast', color='black', linestyle='--')

plt.title("NYC Taxi Demand Forecast - XGBoost", fontsize=18, fontweight='bold')
plt.xlabel("Time (Hours)", fontsize=14)
plt.ylabel("Trips per Hour", fontsize=14)
plt.legend()
plt.grid(alpha=0.3, linestyle='--')
plt.gca().set_facecolor("#FFF8E7")  # soft yellow NYC theme
plt.show()

# example: map preds back to timestamps of X_test
# assume X_test_df contains 'ds' timestamps aligned with preds
X_test_df = X_test.copy().reset_index(drop=True)
X_test_df['ds'] = merged.iloc[split:]['ds'].reset_index(drop=True)
X_test_df['forecast'] = preds
# merge forecasts back to merged
merged = merged.merge(X_test_df[['ds','forecast']], on='ds', how='left', suffixes=('','_new'))
merged['forecast'] = merged['forecast'].fillna(merged.pop('forecast_new'))  # replace or use existing

import numpy as np
import pandas as pd

# ✅ Ensure timestamp is datetime
df['pickup_hour'] = pd.to_datetime(df['pickup_hour'])

# ✅ Create fresh final dataframe
final_df = df.copy()

# ✅ Insert forecast values for ONLY the test rows
final_df['forecast'] = np.nan
final_df.loc[y_test.index, 'forecast'] = y_pred

# ✅ Compute error only where forecast exists
final_df['error'] = np.nan
mask = final_df['forecast'].notna()
final_df.loc[mask, 'error'] = final_df.loc[mask, 'trip_count'] - final_df.loc[mask, 'forecast']

# ✅ Add indicator for BI visuals
final_df['is_forecast'] = final_df['forecast'].notna().astype(int)

# ✅ Add datetime features
final_df['hour'] = final_df['pickup_hour'].dt.hour
final_df['weekday'] = final_df['pickup_hour'].dt.weekday
final_df['day'] = final_df['pickup_hour'].dt.day
final_df['is_weekend'] = final_df['weekday'].isin([5,6]).astype(int)

# ✅ Save final CSV
out_path = "/content/nyc_taxi_forecast_7day.csv"
final_df.to_csv(out_path, index=False)

# ✅ Preview
final_df.tail(15), final_df['forecast'].notna().sum(), final_df['error'].notna().sum()

test = pd.read_csv("/content/nyc_taxi_forecast_7day.csv")
test.tail(15)
test[['forecast','error']].notna().sum()

powerbi_df = final_df.copy()

out_file = "/content/nyc_taxi_powerbi_ready_updated.csv"
powerbi_df.to_csv(out_file, index=False)

out_file

final_df[['pickup_hour','trip_count','forecast','error']].tail(20)